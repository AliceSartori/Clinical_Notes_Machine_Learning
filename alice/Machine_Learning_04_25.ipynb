{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from numpy.random import seed\n",
    "seed(1)\n",
    "from matplotlib import style\n",
    "style.use('fivethirtyeight')\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#!pip install nltk\n",
    "import nltk\n",
    "# nltk.download('punkt')\n",
    "# nltk.download('stopwords')\n",
    "# nltk.download('averaged_perceptron_tagger')\n",
    "# nltk.download('tagsets')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Read the CSV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>description</th>\n",
       "      <th>medical_specialty</th>\n",
       "      <th>sample_name</th>\n",
       "      <th>transcription</th>\n",
       "      <th>keywords</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>A 23-year-old white female presents with comp...</td>\n",
       "      <td>Allergy / Immunology</td>\n",
       "      <td>Allergic Rhinitis</td>\n",
       "      <td>SUBJECTIVE:,  This 23-year-old white female pr...</td>\n",
       "      <td>allergy / immunology, allergic rhinitis, aller...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Consult for laparoscopic gastric bypass.</td>\n",
       "      <td>Bariatrics</td>\n",
       "      <td>Laparoscopic Gastric Bypass Consult - 2</td>\n",
       "      <td>PAST MEDICAL HISTORY:, He has difficulty climb...</td>\n",
       "      <td>bariatrics, laparoscopic gastric bypass, weigh...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Consult for laparoscopic gastric bypass.</td>\n",
       "      <td>Bariatrics</td>\n",
       "      <td>Laparoscopic Gastric Bypass Consult - 1</td>\n",
       "      <td>HISTORY OF PRESENT ILLNESS: , I have seen ABC ...</td>\n",
       "      <td>bariatrics, laparoscopic gastric bypass, heart...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2-D M-Mode. Doppler.</td>\n",
       "      <td>Cardiovascular / Pulmonary</td>\n",
       "      <td>2-D Echocardiogram - 1</td>\n",
       "      <td>2-D M-MODE: , ,1.  Left atrial enlargement wit...</td>\n",
       "      <td>cardiovascular / pulmonary, 2-d m-mode, dopple...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2-D Echocardiogram</td>\n",
       "      <td>Cardiovascular / Pulmonary</td>\n",
       "      <td>2-D Echocardiogram - 2</td>\n",
       "      <td>1.  The left ventricular cavity size and wall ...</td>\n",
       "      <td>cardiovascular / pulmonary, 2-d, doppler, echo...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4994</th>\n",
       "      <td>Patient having severe sinusitis about two to ...</td>\n",
       "      <td>Allergy / Immunology</td>\n",
       "      <td>Chronic Sinusitis</td>\n",
       "      <td>HISTORY:,  I had the pleasure of meeting and e...</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4995</th>\n",
       "      <td>This is a 14-month-old baby boy Caucasian who...</td>\n",
       "      <td>Allergy / Immunology</td>\n",
       "      <td>Kawasaki Disease - Discharge Summary</td>\n",
       "      <td>ADMITTING DIAGNOSIS: , Kawasaki disease.,DISCH...</td>\n",
       "      <td>allergy / immunology, mucous membranes, conjun...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4996</th>\n",
       "      <td>A female for a complete physical and follow u...</td>\n",
       "      <td>Allergy / Immunology</td>\n",
       "      <td>Followup on Asthma</td>\n",
       "      <td>SUBJECTIVE: , This is a 42-year-old white fema...</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4997</th>\n",
       "      <td>Mother states he has been wheezing and coughing.</td>\n",
       "      <td>Allergy / Immunology</td>\n",
       "      <td>Asthma in a 5-year-old</td>\n",
       "      <td>CHIEF COMPLAINT: , This 5-year-old male presen...</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4998</th>\n",
       "      <td>Acute allergic reaction, etiology uncertain, ...</td>\n",
       "      <td>Allergy / Immunology</td>\n",
       "      <td>Allergy Evaluation Consult</td>\n",
       "      <td>HISTORY: , A 34-year-old male presents today s...</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>4999 rows Ã— 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                            description  \\\n",
       "0      A 23-year-old white female presents with comp...   \n",
       "1              Consult for laparoscopic gastric bypass.   \n",
       "2              Consult for laparoscopic gastric bypass.   \n",
       "3                                2-D M-Mode. Doppler.     \n",
       "4                                    2-D Echocardiogram   \n",
       "...                                                 ...   \n",
       "4994   Patient having severe sinusitis about two to ...   \n",
       "4995   This is a 14-month-old baby boy Caucasian who...   \n",
       "4996   A female for a complete physical and follow u...   \n",
       "4997   Mother states he has been wheezing and coughing.   \n",
       "4998   Acute allergic reaction, etiology uncertain, ...   \n",
       "\n",
       "                medical_specialty                                sample_name  \\\n",
       "0            Allergy / Immunology                         Allergic Rhinitis    \n",
       "1                      Bariatrics   Laparoscopic Gastric Bypass Consult - 2    \n",
       "2                      Bariatrics   Laparoscopic Gastric Bypass Consult - 1    \n",
       "3      Cardiovascular / Pulmonary                    2-D Echocardiogram - 1    \n",
       "4      Cardiovascular / Pulmonary                    2-D Echocardiogram - 2    \n",
       "...                           ...                                        ...   \n",
       "4994         Allergy / Immunology                         Chronic Sinusitis    \n",
       "4995         Allergy / Immunology      Kawasaki Disease - Discharge Summary    \n",
       "4996         Allergy / Immunology                        Followup on Asthma    \n",
       "4997         Allergy / Immunology                    Asthma in a 5-year-old    \n",
       "4998         Allergy / Immunology                Allergy Evaluation Consult    \n",
       "\n",
       "                                          transcription  \\\n",
       "0     SUBJECTIVE:,  This 23-year-old white female pr...   \n",
       "1     PAST MEDICAL HISTORY:, He has difficulty climb...   \n",
       "2     HISTORY OF PRESENT ILLNESS: , I have seen ABC ...   \n",
       "3     2-D M-MODE: , ,1.  Left atrial enlargement wit...   \n",
       "4     1.  The left ventricular cavity size and wall ...   \n",
       "...                                                 ...   \n",
       "4994  HISTORY:,  I had the pleasure of meeting and e...   \n",
       "4995  ADMITTING DIAGNOSIS: , Kawasaki disease.,DISCH...   \n",
       "4996  SUBJECTIVE: , This is a 42-year-old white fema...   \n",
       "4997  CHIEF COMPLAINT: , This 5-year-old male presen...   \n",
       "4998  HISTORY: , A 34-year-old male presents today s...   \n",
       "\n",
       "                                               keywords  \n",
       "0     allergy / immunology, allergic rhinitis, aller...  \n",
       "1     bariatrics, laparoscopic gastric bypass, weigh...  \n",
       "2     bariatrics, laparoscopic gastric bypass, heart...  \n",
       "3     cardiovascular / pulmonary, 2-d m-mode, dopple...  \n",
       "4     cardiovascular / pulmonary, 2-d, doppler, echo...  \n",
       "...                                                 ...  \n",
       "4994                                                NaN  \n",
       "4995  allergy / immunology, mucous membranes, conjun...  \n",
       "4996                                                NaN  \n",
       "4997                                                NaN  \n",
       "4998                                                NaN  \n",
       "\n",
       "[4999 rows x 5 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data= pd.read_csv(\"mtsamples 4.csv\", index_col=[0])\n",
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 4999 entries, 0 to 4998\n",
      "Data columns (total 5 columns):\n",
      " #   Column             Non-Null Count  Dtype \n",
      "---  ------             --------------  ----- \n",
      " 0   description        4999 non-null   object\n",
      " 1   medical_specialty  4999 non-null   object\n",
      " 2   sample_name        4999 non-null   object\n",
      " 3   transcription      4966 non-null   object\n",
      " 4   keywords           3931 non-null   object\n",
      "dtypes: object(5)\n",
      "memory usage: 234.3+ KB\n"
     ]
    }
   ],
   "source": [
    "data.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "del data['keywords']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 4999 entries, 0 to 4998\n",
      "Data columns (total 4 columns):\n",
      " #   Column             Non-Null Count  Dtype \n",
      "---  ------             --------------  ----- \n",
      " 0   description        4999 non-null   object\n",
      " 1   medical_specialty  4999 non-null   object\n",
      " 2   sample_name        4999 non-null   object\n",
      " 3   transcription      4966 non-null   object\n",
      "dtypes: object(4)\n",
      "memory usage: 195.3+ KB\n"
     ]
    }
   ],
   "source": [
    "data.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "description           0\n",
       "medical_specialty     0\n",
       "sample_name           0\n",
       "transcription        33\n",
       "dtype: int64"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>description</th>\n",
       "      <th>medical_specialty</th>\n",
       "      <th>sample_name</th>\n",
       "      <th>transcription</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>3287</th>\n",
       "      <td>History of diabetes, osteoarthritis, atrial f...</td>\n",
       "      <td>General Medicine</td>\n",
       "      <td>H&amp;P - Gen Med - 2</td>\n",
       "      <td>HISTORY OF PRESENT ILLNESS:, The patient is a ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2592</th>\n",
       "      <td>Exam under anesthesia.  Removal of intrauteri...</td>\n",
       "      <td>Obstetrics / Gynecology</td>\n",
       "      <td>Intrauterine Clots Removal</td>\n",
       "      <td>PREOPERATIVE DIAGNOSIS: , Postpartum hemorrhag...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1909</th>\n",
       "      <td>Template for History and Physical for a newborn.</td>\n",
       "      <td>Pediatrics - Neonatal</td>\n",
       "      <td>Normal Newborn H&amp;P Template</td>\n",
       "      <td>HISTORY OF PRESENT ILLNESS: , This is a ** wee...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4934</th>\n",
       "      <td>Flexible Bronchoscopy (pediatric)</td>\n",
       "      <td>Cardiovascular / Pulmonary</td>\n",
       "      <td>Bronchoscopy - Pediatric</td>\n",
       "      <td>FLEXIBLE BRONCHOSCOPY,The flexible bronchoscop...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3838</th>\n",
       "      <td>Head injury, anxiety, and hypertensive emerge...</td>\n",
       "      <td>Emergency Room Reports</td>\n",
       "      <td>Head Injury</td>\n",
       "      <td>CHIEF COMPLAINT:,  Head injury.,HISTORY: , Thi...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                            description  \\\n",
       "3287   History of diabetes, osteoarthritis, atrial f...   \n",
       "2592   Exam under anesthesia.  Removal of intrauteri...   \n",
       "1909   Template for History and Physical for a newborn.   \n",
       "4934                  Flexible Bronchoscopy (pediatric)   \n",
       "3838   Head injury, anxiety, and hypertensive emerge...   \n",
       "\n",
       "                medical_specialty                    sample_name  \\\n",
       "3287             General Medicine             H&P - Gen Med - 2    \n",
       "2592      Obstetrics / Gynecology    Intrauterine Clots Removal    \n",
       "1909        Pediatrics - Neonatal   Normal Newborn H&P Template    \n",
       "4934   Cardiovascular / Pulmonary      Bronchoscopy - Pediatric    \n",
       "3838       Emergency Room Reports                   Head Injury    \n",
       "\n",
       "                                          transcription  \n",
       "3287  HISTORY OF PRESENT ILLNESS:, The patient is a ...  \n",
       "2592  PREOPERATIVE DIAGNOSIS: , Postpartum hemorrhag...  \n",
       "1909  HISTORY OF PRESENT ILLNESS: , This is a ** wee...  \n",
       "4934  FLEXIBLE BRONCHOSCOPY,The flexible bronchoscop...  \n",
       "3838  CHIEF COMPLAINT:,  Head injury.,HISTORY: , Thi...  "
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data= data.dropna(axis = 0, how ='any') \n",
    "data.sample(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "description          0\n",
       "medical_specialty    0\n",
       "sample_name          0\n",
       "transcription        0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0       SUBJECTIVE:,  This 23-year-old white female pr...\n",
       "1       PAST MEDICAL HISTORY:, He has difficulty climb...\n",
       "2       HISTORY OF PRESENT ILLNESS: , I have seen ABC ...\n",
       "3       2-D M-MODE: , ,1.  Left atrial enlargement wit...\n",
       "4       1.  The left ventricular cavity size and wall ...\n",
       "                              ...                        \n",
       "4994    HISTORY:,  I had the pleasure of meeting and e...\n",
       "4995    ADMITTING DIAGNOSIS: , Kawasaki disease.,DISCH...\n",
       "4996    SUBJECTIVE: , This is a 42-year-old white fema...\n",
       "4997    CHIEF COMPLAINT: , This 5-year-old male presen...\n",
       "4998    HISTORY: , A 34-year-old male presents today s...\n",
       "Name: transcription, Length: 4966, dtype: object"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data['transcription']=data['transcription'].astype('str')\n",
    "data['transcription']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0       subjective:,  this 23-year-old white female pr...\n",
       "1       past medical history:, he has difficulty climb...\n",
       "2       history of present illness: , i have seen abc ...\n",
       "3       2-d m-mode: , ,1.  left atrial enlargement wit...\n",
       "4       1.  the left ventricular cavity size and wall ...\n",
       "                              ...                        \n",
       "4994    history:,  i had the pleasure of meeting and e...\n",
       "4995    admitting diagnosis: , kawasaki disease.,disch...\n",
       "4996    subjective: , this is a 42-year-old white fema...\n",
       "4997    chief complaint: , this 5-year-old male presen...\n",
       "4998    history: , a 34-year-old male presents today s...\n",
       "Name: transcription, Length: 4966, dtype: object"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data['transcription'] = data['transcription'].str.lower()\n",
    "data['transcription']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# data['transcription'].replace(['#'], [' '], regex=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>description</th>\n",
       "      <th>medical_specialty</th>\n",
       "      <th>sample_name</th>\n",
       "      <th>transcription</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2870</th>\n",
       "      <td>Headache.  Right frontal lobe glioma.</td>\n",
       "      <td>Neurology</td>\n",
       "      <td>Glioma - 2</td>\n",
       "      <td>cc headache,hxy/o rhf presented to her local p...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>780</th>\n",
       "      <td>Cellulitis with associated abscess and foreig...</td>\n",
       "      <td>Surgery</td>\n",
       "      <td>Foreign Body Removal - Foot - 1</td>\n",
       "      <td>preoperative diagnoses cellulitis with associa...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3432</th>\n",
       "      <td>A 2-month-old female with 1-week history of c...</td>\n",
       "      <td>General Medicine</td>\n",
       "      <td>Congestion &amp; Fever - 2-month-old</td>\n",
       "      <td>chief complaint  a 2-month-old female with 1-w...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1645</th>\n",
       "      <td>Patient with a past medical history of a left...</td>\n",
       "      <td>Radiology</td>\n",
       "      <td>EMG/Nerve Conduction Study - 6</td>\n",
       "      <td>history  the patient is a 46-year-old right-ha...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4938</th>\n",
       "      <td>Plastic piece foreign body in the right main...</td>\n",
       "      <td>Cardiovascular / Pulmonary</td>\n",
       "      <td>Bronchoscopy &amp; Foreign Body Removal</td>\n",
       "      <td>preoperative diagnosis foreign body in airway....</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                            description  \\\n",
       "2870              Headache.  Right frontal lobe glioma.   \n",
       "780    Cellulitis with associated abscess and foreig...   \n",
       "3432   A 2-month-old female with 1-week history of c...   \n",
       "1645   Patient with a past medical history of a left...   \n",
       "4938    Plastic piece foreign body in the right main...   \n",
       "\n",
       "                medical_specialty                            sample_name  \\\n",
       "2870                    Neurology                            Glioma - 2    \n",
       "780                       Surgery       Foreign Body Removal - Foot - 1    \n",
       "3432             General Medicine      Congestion & Fever - 2-month-old    \n",
       "1645                    Radiology        EMG/Nerve Conduction Study - 6    \n",
       "4938   Cardiovascular / Pulmonary   Bronchoscopy & Foreign Body Removal    \n",
       "\n",
       "                                          transcription  \n",
       "2870  cc headache,hxy/o rhf presented to her local p...  \n",
       "780   preoperative diagnoses cellulitis with associa...  \n",
       "3432  chief complaint  a 2-month-old female with 1-w...  \n",
       "1645  history  the patient is a 46-year-old right-ha...  \n",
       "4938  preoperative diagnosis foreign body in airway....  "
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#getting rid of targeted charachters in the trascription\n",
    "chars = ['#',':,',': ,',';','$','!','?','*','``','1. ', '2. ', '3. ', '4. ', '5. ','6. ','7. ','8. ','9. ','10. ']\n",
    "for c in chars:\n",
    "    data['transcription'] = data['transcription'].str.replace(c,\"\")\n",
    "\n",
    "data.sample(5)\n",
    "\n",
    "# chars = \"\\`*_{}[]()>#+-.,!$:;%'&/?\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>description</th>\n",
       "      <th>medical_specialty</th>\n",
       "      <th>sample_name</th>\n",
       "      <th>transcription</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1983</th>\n",
       "      <td>Knee injection</td>\n",
       "      <td>Pain Management</td>\n",
       "      <td>Knee Injection</td>\n",
       "      <td>the patient was told that the injection may ca...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>69</th>\n",
       "      <td>The patient is a 16-month-old boy, who had a ...</td>\n",
       "      <td>Urology</td>\n",
       "      <td>Penile Cellulitis</td>\n",
       "      <td>chief complaint    penile cellulitis status po...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>757</th>\n",
       "      <td>Removal of painful hardware, first left metat...</td>\n",
       "      <td>Surgery</td>\n",
       "      <td>Hardware Removal - Metatarsal</td>\n",
       "      <td>title of operation removal of painful hardware...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4546</th>\n",
       "      <td>Left buttock abscess, status post incision an...</td>\n",
       "      <td>Consult - History and Phy.</td>\n",
       "      <td>Buttock Abscess</td>\n",
       "      <td>chief complaint buttock abscess  history of pr...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1946</th>\n",
       "      <td>1+ year, black female for initial evaluation ...</td>\n",
       "      <td>Pediatrics - Neonatal</td>\n",
       "      <td>Atopic Eczema</td>\n",
       "      <td>subjective  this year  black female  new patie...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                            description  \\\n",
       "1983                                     Knee injection   \n",
       "69     The patient is a 16-month-old boy, who had a ...   \n",
       "757    Removal of painful hardware, first left metat...   \n",
       "4546   Left buttock abscess, status post incision an...   \n",
       "1946   1+ year, black female for initial evaluation ...   \n",
       "\n",
       "                medical_specialty                      sample_name  \\\n",
       "1983              Pain Management                  Knee Injection    \n",
       "69                        Urology               Penile Cellulitis    \n",
       "757                       Surgery   Hardware Removal - Metatarsal    \n",
       "4546   Consult - History and Phy.                 Buttock Abscess    \n",
       "1946        Pediatrics - Neonatal                   Atopic Eczema    \n",
       "\n",
       "                                          transcription  \n",
       "1983  the patient was told that the injection may ca...  \n",
       "69    chief complaint    penile cellulitis status po...  \n",
       "757   title of operation removal of painful hardware...  \n",
       "4546  chief complaint buttock abscess  history of pr...  \n",
       "1946  subjective  this year  black female  new patie...  "
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#getting rid of targeted charachters in the trascription\n",
    "chars = [\",\", \".\", \"[\", \"]\", \":\", \"``\", \")\", \"(\", \"1\", \"2\", \"5\", \"%\", \"3\", \"4\", \"4-0\", \"3-0\", \"6\", \"''\", \"0\", \"2-0\", \"8\", \"7\", \"&\", \"5-0\", \"9\", \"0.5\", \"1.5\", \"500\", \"50\", \"100\", \"6-0\", \"15\", \"2.5\", \"14-15\", \"60\", \"'\", \"300\", \"14\", \"________\", \"7-0\", \"90\", \"__________\", \"3.5\", \"1:100,000\", \"70\", \"0.\", \"80\", \"1:50,000\", \"03/08/200 \", \"03/09/2007\", \"25605\", \"7.314\", \"33.0\", \"855.\", \"08/22/03\", \"10/500\", \"125.\", \"144/6\"]\n",
    "for c in chars:\n",
    "    data['transcription'] = data['transcription'].str.replace(c,\" \")\n",
    "\n",
    "data.sample(5)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>description</th>\n",
       "      <th>medical_specialty</th>\n",
       "      <th>sample_name</th>\n",
       "      <th>transcription</th>\n",
       "      <th>tokenized_sents</th>\n",
       "      <th>POSTags</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2519</th>\n",
       "      <td>Ultrasound OB - followup for fetal growth.</td>\n",
       "      <td>Obstetrics / Gynecology</td>\n",
       "      <td>Ultrasound OB</td>\n",
       "      <td>reason for exam followup for fetal growth     ...</td>\n",
       "      <td>[reason, for, exam, followup, for, fetal, grow...</td>\n",
       "      <td>[([, JJ), ('reason, NNP), (', POS), (,, ,), ('...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3362</th>\n",
       "      <td>Patient in with mom for possible ear infection.</td>\n",
       "      <td>General Medicine</td>\n",
       "      <td>Gen Med Consult - 23</td>\n",
       "      <td>subjective  mom brings the patient in today fo...</td>\n",
       "      <td>[subjective, mom, brings, the, patient, in, to...</td>\n",
       "      <td>[([, RB), ('subjective, JJ), (', ''), (,, ,), ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3658</th>\n",
       "      <td>Colonoscopy due to rectal bleeding, constipat...</td>\n",
       "      <td>Gastroenterology</td>\n",
       "      <td>Colonoscopy - 1</td>\n",
       "      <td>indication  rectal bleeding  constipation  abn...</td>\n",
       "      <td>[indication, rectal, bleeding, constipation, a...</td>\n",
       "      <td>[([, JJ), ('indication, NN), (', ''), (,, ,), ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>The patient noted for improving retention of ...</td>\n",
       "      <td>Urology</td>\n",
       "      <td>Urinary Retention - Followup</td>\n",
       "      <td>history of present illness the patient present...</td>\n",
       "      <td>[history, of, present, illness, the, patient, ...</td>\n",
       "      <td>[([, JJ), ('history, NN), (', ''), (,, ,), ('o...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3579</th>\n",
       "      <td>EGD with dilation for dysphagia.</td>\n",
       "      <td>Gastroenterology</td>\n",
       "      <td>EGD with Dilation</td>\n",
       "      <td>indication</td>\n",
       "      <td>[indication]</td>\n",
       "      <td>[([, JJ), ('indication, NN), (', POS), (], NN)]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                            description  \\\n",
       "2519         Ultrasound OB - followup for fetal growth.   \n",
       "3362    Patient in with mom for possible ear infection.   \n",
       "3658   Colonoscopy due to rectal bleeding, constipat...   \n",
       "30     The patient noted for improving retention of ...   \n",
       "3579                   EGD with dilation for dysphagia.   \n",
       "\n",
       "             medical_specialty                     sample_name  \\\n",
       "2519   Obstetrics / Gynecology                  Ultrasound OB    \n",
       "3362          General Medicine           Gen Med Consult - 23    \n",
       "3658          Gastroenterology                Colonoscopy - 1    \n",
       "30                     Urology   Urinary Retention - Followup    \n",
       "3579          Gastroenterology              EGD with Dilation    \n",
       "\n",
       "                                          transcription  \\\n",
       "2519  reason for exam followup for fetal growth     ...   \n",
       "3362  subjective  mom brings the patient in today fo...   \n",
       "3658  indication  rectal bleeding  constipation  abn...   \n",
       "30    history of present illness the patient present...   \n",
       "3579                                     indication       \n",
       "\n",
       "                                        tokenized_sents  \\\n",
       "2519  [reason, for, exam, followup, for, fetal, grow...   \n",
       "3362  [subjective, mom, brings, the, patient, in, to...   \n",
       "3658  [indication, rectal, bleeding, constipation, a...   \n",
       "30    [history, of, present, illness, the, patient, ...   \n",
       "3579                                       [indication]   \n",
       "\n",
       "                                                POSTags  \n",
       "2519  [([, JJ), ('reason, NNP), (', POS), (,, ,), ('...  \n",
       "3362  [([, RB), ('subjective, JJ), (', ''), (,, ,), ...  \n",
       "3658  [([, JJ), ('indication, NN), (', ''), (,, ,), ...  \n",
       "30    [([, JJ), ('history, NN), (', ''), (,, ,), ('o...  \n",
       "3579    [([, JJ), ('indication, NN), (', POS), (], NN)]  "
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Tokenizing \n",
    "from nltk.tokenize import word_tokenize\n",
    "\n",
    "data['tokenized_sents'] = data['transcription'].apply(nltk.word_tokenize)\n",
    "data.sample(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# data[\"tokenized_sents\"] = data[\"tokenized_sents\"].astype('str')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'subjective'"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data[\"tokenized_sents\"][0][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('subjective', 'NN'),\n",
       " ('this', 'DT'),\n",
       " ('-year-old', 'JJ'),\n",
       " ('white', 'JJ'),\n",
       " ('female', 'NN'),\n",
       " ('presents', 'NNS'),\n",
       " ('with', 'IN'),\n",
       " ('complaint', 'NN'),\n",
       " ('of', 'IN'),\n",
       " ('allergies', 'NNS'),\n",
       " ('she', 'PRP'),\n",
       " ('used', 'VBD'),\n",
       " ('to', 'TO'),\n",
       " ('have', 'VB'),\n",
       " ('allergies', 'NNS'),\n",
       " ('when', 'WRB'),\n",
       " ('she', 'PRP'),\n",
       " ('lived', 'VBD'),\n",
       " ('in', 'IN'),\n",
       " ('seattle', 'NN'),\n",
       " ('but', 'CC'),\n",
       " ('she', 'PRP'),\n",
       " ('thinks', 'VBZ'),\n",
       " ('they', 'PRP'),\n",
       " ('are', 'VBP'),\n",
       " ('worse', 'JJR'),\n",
       " ('here', 'RB'),\n",
       " ('in', 'IN'),\n",
       " ('the', 'DT'),\n",
       " ('past', 'JJ'),\n",
       " ('she', 'PRP'),\n",
       " ('has', 'VBZ'),\n",
       " ('tried', 'VBN'),\n",
       " ('claritin', 'NN'),\n",
       " ('and', 'CC'),\n",
       " ('zyrtec', 'NN'),\n",
       " ('both', 'DT'),\n",
       " ('worked', 'VBD'),\n",
       " ('for', 'IN'),\n",
       " ('short', 'JJ'),\n",
       " ('time', 'NN'),\n",
       " ('but', 'CC'),\n",
       " ('then', 'RB'),\n",
       " ('seemed', 'VBD'),\n",
       " ('to', 'TO'),\n",
       " ('lose', 'VB'),\n",
       " ('effectiveness', 'NN'),\n",
       " ('she', 'PRP'),\n",
       " ('has', 'VBZ'),\n",
       " ('used', 'VBN'),\n",
       " ('allegra', 'NN'),\n",
       " ('also', 'RB'),\n",
       " ('she', 'PRP'),\n",
       " ('used', 'VBD'),\n",
       " ('that', 'IN'),\n",
       " ('last', 'JJ'),\n",
       " ('summer', 'NN'),\n",
       " ('and', 'CC'),\n",
       " ('she', 'PRP'),\n",
       " ('began', 'VBD'),\n",
       " ('using', 'VBG'),\n",
       " ('it', 'PRP'),\n",
       " ('again', 'RB'),\n",
       " ('two', 'CD'),\n",
       " ('weeks', 'NNS'),\n",
       " ('ago', 'IN'),\n",
       " ('it', 'PRP'),\n",
       " ('does', 'VBZ'),\n",
       " ('not', 'RB'),\n",
       " ('appear', 'VB'),\n",
       " ('to', 'TO'),\n",
       " ('be', 'VB'),\n",
       " ('working', 'VBG'),\n",
       " ('very', 'RB'),\n",
       " ('well', 'RB'),\n",
       " ('she', 'PRP'),\n",
       " ('has', 'VBZ'),\n",
       " ('used', 'VBN'),\n",
       " ('over-the-counter', 'JJ'),\n",
       " ('sprays', 'NNS'),\n",
       " ('but', 'CC'),\n",
       " ('no', 'DT'),\n",
       " ('prescription', 'NN'),\n",
       " ('nasal', 'NN'),\n",
       " ('sprays', 'VBZ'),\n",
       " ('she', 'PRP'),\n",
       " ('does', 'VBZ'),\n",
       " ('have', 'VB'),\n",
       " ('asthma', 'VBN'),\n",
       " ('but', 'CC'),\n",
       " ('doest', 'JJS'),\n",
       " ('not', 'RB'),\n",
       " ('require', 'VB'),\n",
       " ('daily', 'JJ'),\n",
       " ('medication', 'NN'),\n",
       " ('for', 'IN'),\n",
       " ('this', 'DT'),\n",
       " ('and', 'CC'),\n",
       " ('does', 'VBZ'),\n",
       " ('not', 'RB'),\n",
       " ('think', 'VB'),\n",
       " ('it', 'PRP'),\n",
       " ('is', 'VBZ'),\n",
       " ('flaring', 'VBG'),\n",
       " ('up', 'RP'),\n",
       " ('medications', 'NNS'),\n",
       " ('her', 'PRP$'),\n",
       " ('only', 'JJ'),\n",
       " ('medication', 'NN'),\n",
       " ('currently', 'RB'),\n",
       " ('is', 'VBZ'),\n",
       " ('ortho', 'JJ'),\n",
       " ('tri-cyclen', 'JJ'),\n",
       " ('and', 'CC'),\n",
       " ('the', 'DT'),\n",
       " ('allegra', 'NN'),\n",
       " ('allergies', 'VBZ'),\n",
       " ('she', 'PRP'),\n",
       " ('has', 'VBZ'),\n",
       " ('no', 'DT'),\n",
       " ('known', 'VBN'),\n",
       " ('medicine', 'NN'),\n",
       " ('allergies', 'NNS'),\n",
       " ('objectivevitals', 'NNS'),\n",
       " ('weight', 'VBD'),\n",
       " ('was', 'VBD'),\n",
       " ('pounds', 'NNS'),\n",
       " ('and', 'CC'),\n",
       " ('blood', 'NN'),\n",
       " ('pressure', 'NN'),\n",
       " ('/', 'NNP'),\n",
       " ('heent', 'NN'),\n",
       " ('her', 'PRP$'),\n",
       " ('throat', 'NN'),\n",
       " ('was', 'VBD'),\n",
       " ('mildly', 'RB'),\n",
       " ('erythematous', 'JJ'),\n",
       " ('without', 'IN'),\n",
       " ('exudate', 'JJ'),\n",
       " ('nasal', 'NN'),\n",
       " ('mucosa', 'NN'),\n",
       " ('was', 'VBD'),\n",
       " ('erythematous', 'JJ'),\n",
       " ('and', 'CC'),\n",
       " ('swollen', 'VBZ'),\n",
       " ('only', 'RB'),\n",
       " ('clear', 'JJ'),\n",
       " ('drainage', 'NN'),\n",
       " ('was', 'VBD'),\n",
       " ('seen', 'VBN'),\n",
       " ('tms', 'NNS'),\n",
       " ('were', 'VBD'),\n",
       " ('clear', 'JJ'),\n",
       " ('neck', 'NN'),\n",
       " ('supple', 'NN'),\n",
       " ('without', 'IN'),\n",
       " ('adenopathy', 'JJ'),\n",
       " ('lungs', 'NNS'),\n",
       " ('clear', 'JJ'),\n",
       " ('assessment', 'JJ'),\n",
       " ('allergic', 'NN'),\n",
       " ('rhinitis', 'NN'),\n",
       " ('plan', 'NN'),\n",
       " ('she', 'PRP'),\n",
       " ('will', 'MD'),\n",
       " ('try', 'VB'),\n",
       " ('zyrtec', 'JJ'),\n",
       " ('instead', 'RB'),\n",
       " ('of', 'IN'),\n",
       " ('allegra', 'NN'),\n",
       " ('again', 'RB'),\n",
       " ('another', 'DT'),\n",
       " ('option', 'NN'),\n",
       " ('will', 'MD'),\n",
       " ('be', 'VB'),\n",
       " ('to', 'TO'),\n",
       " ('use', 'VB'),\n",
       " ('loratadine', 'JJ'),\n",
       " ('she', 'PRP'),\n",
       " ('does', 'VBZ'),\n",
       " ('not', 'RB'),\n",
       " ('think', 'VB'),\n",
       " ('she', 'PRP'),\n",
       " ('has', 'VBZ'),\n",
       " ('prescription', 'NN'),\n",
       " ('coverage', 'NN'),\n",
       " ('so', 'RB'),\n",
       " ('that', 'IN'),\n",
       " ('might', 'MD'),\n",
       " ('be', 'VB'),\n",
       " ('cheaper', 'JJR'),\n",
       " ('samples', 'NNS'),\n",
       " ('of', 'IN'),\n",
       " ('nasonex', 'JJ'),\n",
       " ('two', 'CD'),\n",
       " ('sprays', 'NNS'),\n",
       " ('in', 'IN'),\n",
       " ('each', 'DT'),\n",
       " ('nostril', 'NN'),\n",
       " ('given', 'VBN'),\n",
       " ('for', 'IN'),\n",
       " ('three', 'CD'),\n",
       " ('weeks', 'NNS'),\n",
       " ('a', 'DT'),\n",
       " ('prescription', 'NN'),\n",
       " ('was', 'VBD'),\n",
       " ('written', 'VBN'),\n",
       " ('as', 'RB'),\n",
       " ('well', 'RB')]"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nltk.tag.pos_tag(data[\"tokenized_sents\"][0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "data['POSTags'] = data['tokenized_sents'].apply(pos_tag)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    [(subjective, NN), (this, DT), (-year-old, JJ)...\n",
       "1    [(past, JJ), (medical, JJ), (history, NN), (he...\n",
       "2    [(history, NN), (of, IN), (present, JJ), (illn...\n",
       "3    [(-d, JJ), (m-mode, NN), (left, VBD), (atrial,...\n",
       "4    [(the, DT), (left, NN), (ventricular, JJ), (ca...\n",
       "Name: POSTags, dtype: object"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data['POSTags'].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('subjective', 'NN'),\n",
       " ('female', 'NN'),\n",
       " ('presents', 'NNS'),\n",
       " ('complaint', 'NN'),\n",
       " ('allergies', 'NNS'),\n",
       " ('allergies', 'NNS'),\n",
       " ('seattle', 'NN'),\n",
       " ('claritin', 'NN'),\n",
       " ('zyrtec', 'NN'),\n",
       " ('time', 'NN'),\n",
       " ('effectiveness', 'NN'),\n",
       " ('allegra', 'NN'),\n",
       " ('summer', 'NN'),\n",
       " ('weeks', 'NNS'),\n",
       " ('sprays', 'NNS'),\n",
       " ('prescription', 'NN'),\n",
       " ('nasal', 'NN'),\n",
       " ('medication', 'NN'),\n",
       " ('medications', 'NNS'),\n",
       " ('medication', 'NN'),\n",
       " ('allegra', 'NN'),\n",
       " ('medicine', 'NN'),\n",
       " ('allergies', 'NNS'),\n",
       " ('objectivevitals', 'NNS'),\n",
       " ('pounds', 'NNS'),\n",
       " ('blood', 'NN'),\n",
       " ('pressure', 'NN'),\n",
       " ('/', 'NNP'),\n",
       " ('heent', 'NN'),\n",
       " ('throat', 'NN'),\n",
       " ('nasal', 'NN'),\n",
       " ('mucosa', 'NN'),\n",
       " ('drainage', 'NN'),\n",
       " ('tms', 'NNS'),\n",
       " ('neck', 'NN'),\n",
       " ('supple', 'NN'),\n",
       " ('lungs', 'NNS'),\n",
       " ('allergic', 'NN'),\n",
       " ('rhinitis', 'NN'),\n",
       " ('plan', 'NN'),\n",
       " ('allegra', 'NN'),\n",
       " ('option', 'NN'),\n",
       " ('prescription', 'NN'),\n",
       " ('coverage', 'NN'),\n",
       " ('samples', 'NNS'),\n",
       " ('sprays', 'NNS'),\n",
       " ('nostril', 'NN'),\n",
       " ('weeks', 'NNS'),\n",
       " ('prescription', 'NN')]"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data['Nouns'] = data['POSTags'].apply(lambda x: [(t[0], t[1]) for t in x if t[1]=='NN' or t[1]=='NNP' or t[1]=='NNS' or t[1]=='NNPS'])\n",
    "\n",
    "\n",
    "data['Nouns'][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'row' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-28-ecfe9d0b6869>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m \u001b[0mdata\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'POSTags'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m=\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'tokenized_sents'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mapply\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpos_tag\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mword_tokenize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrow\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mitem\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrow\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      5\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'row' is not defined"
     ]
    }
   ],
   "source": [
    "from nltk import pos_tag\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "data['POSTags']= data['tokenized_sents'].apply(pos_tag(word_tokenize(row) for item in row))\n",
    "                             \n",
    "\n",
    "# data['POSTags'] = pos_tag(data['tokenized_sents'].apply(word_tokenize))\n",
    "                                                  \n",
    "# data['lemmatize'] = data['post_stopwords'].apply(lambda lst:[lmtzr.lemmatize(word) for word in lst])\n",
    "\n",
    "# .tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(data['POSTags'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('[', 'RB'),\n",
       " (\"'subjective\", 'JJ'),\n",
       " (\"'\", \"''\"),\n",
       " (',', ','),\n",
       " (\"'this\", 'NNP'),\n",
       " (\"'\", 'POS'),\n",
       " (',', ','),\n",
       " (\"'-year-old\", 'JJ'),\n",
       " (\"'\", \"''\"),\n",
       " (',', ','),\n",
       " (\"'white\", 'NNP'),\n",
       " (\"'\", 'POS'),\n",
       " (',', ','),\n",
       " (\"'female\", 'NNP'),\n",
       " (\"'\", 'POS'),\n",
       " (',', ','),\n",
       " (\"'presents\", 'NNS'),\n",
       " (\"'\", 'POS'),\n",
       " (',', ','),\n",
       " (\"'with\", 'NNP'),\n",
       " (\"'\", 'POS'),\n",
       " (',', ','),\n",
       " (\"'complaint\", 'NNP'),\n",
       " (\"'\", 'POS'),\n",
       " (',', ','),\n",
       " (\"'of\", 'NNP'),\n",
       " (\"'\", 'POS'),\n",
       " (',', ','),\n",
       " (\"'allergies\", 'NNS'),\n",
       " (\"'\", 'POS'),\n",
       " (',', ','),\n",
       " (\"'she\", 'NNP'),\n",
       " (\"'\", 'POS'),\n",
       " (',', ','),\n",
       " (\"'used\", 'VBD'),\n",
       " (\"'\", \"''\"),\n",
       " (',', ','),\n",
       " (\"'to\", 'NNP'),\n",
       " (\"'\", 'POS'),\n",
       " (',', ','),\n",
       " (\"'have\", 'VBP'),\n",
       " (\"'\", \"''\"),\n",
       " (',', ','),\n",
       " (\"'allergies\", 'NNS'),\n",
       " (\"'\", 'POS'),\n",
       " (',', ','),\n",
       " (\"'when\", 'NNP'),\n",
       " (\"'\", 'POS'),\n",
       " (',', ','),\n",
       " (\"'she\", 'NNP'),\n",
       " (\"'\", 'POS'),\n",
       " (',', ','),\n",
       " (\"'lived\", 'VBD'),\n",
       " (\"'\", \"''\"),\n",
       " (',', ','),\n",
       " (\"'in\", 'NNP'),\n",
       " (\"'\", 'POS'),\n",
       " (',', ','),\n",
       " (\"'seattle\", 'NNP'),\n",
       " (\"'\", 'POS'),\n",
       " (',', ','),\n",
       " (\"'but\", 'NNP'),\n",
       " (\"'\", 'POS'),\n",
       " (',', ','),\n",
       " (\"'she\", 'NNP'),\n",
       " (\"'\", 'POS'),\n",
       " (',', ','),\n",
       " (\"'thinks\", 'NNS'),\n",
       " (\"'\", 'POS'),\n",
       " (',', ','),\n",
       " (\"'they\", 'NNP'),\n",
       " (\"'\", 'POS'),\n",
       " (',', ','),\n",
       " (\"'are\", 'NNP'),\n",
       " (\"'\", 'POS'),\n",
       " (',', ','),\n",
       " (\"'worse\", \"''\"),\n",
       " (\"'\", \"''\"),\n",
       " (',', ','),\n",
       " (\"'here\", 'EX'),\n",
       " (\"'\", \"''\"),\n",
       " (',', ','),\n",
       " (\"'in\", 'NNP'),\n",
       " (\"'\", 'POS'),\n",
       " (',', ','),\n",
       " (\"'the\", 'NNP'),\n",
       " (\"'\", 'POS'),\n",
       " (',', ','),\n",
       " (\"'past\", \"''\"),\n",
       " (\"'\", \"''\"),\n",
       " (',', ','),\n",
       " (\"'she\", 'NNP'),\n",
       " (\"'\", 'POS'),\n",
       " (',', ','),\n",
       " (\"'has\", 'NNP'),\n",
       " (\"'\", 'POS'),\n",
       " (',', ','),\n",
       " (\"'tried\", 'VBD'),\n",
       " (\"'\", \"''\"),\n",
       " (',', ','),\n",
       " (\"'claritin\", 'NNP'),\n",
       " (\"'\", 'POS'),\n",
       " (',', ','),\n",
       " (\"'and\", 'NNP'),\n",
       " (\"'\", 'POS'),\n",
       " (',', ','),\n",
       " (\"'zyrtec\", \"''\"),\n",
       " (\"'\", \"''\"),\n",
       " (',', ','),\n",
       " (\"'both\", 'DT'),\n",
       " (\"'\", \"''\"),\n",
       " (',', ','),\n",
       " (\"'worked\", 'VBD'),\n",
       " (\"'\", \"''\"),\n",
       " (',', ','),\n",
       " (\"'for\", 'NNP'),\n",
       " (\"'\", 'POS'),\n",
       " (',', ','),\n",
       " (\"'short\", 'NNP'),\n",
       " (\"'\", 'POS'),\n",
       " (',', ','),\n",
       " (\"'time\", 'NNP'),\n",
       " (\"'\", 'POS'),\n",
       " (',', ','),\n",
       " (\"'but\", 'NNP'),\n",
       " (\"'\", 'POS'),\n",
       " (',', ','),\n",
       " (\"'then\", 'NNP'),\n",
       " (\"'\", 'POS'),\n",
       " (',', ','),\n",
       " (\"'seemed\", 'VBD'),\n",
       " (\"'\", \"''\"),\n",
       " (',', ','),\n",
       " (\"'to\", 'NNP'),\n",
       " (\"'\", 'POS'),\n",
       " (',', ','),\n",
       " (\"'lose\", 'NNP'),\n",
       " (\"'\", 'POS'),\n",
       " (',', ','),\n",
       " (\"'effectiveness\", 'NNP'),\n",
       " (\"'\", 'POS'),\n",
       " (',', ','),\n",
       " (\"'she\", 'NNP'),\n",
       " (\"'\", 'POS'),\n",
       " (',', ','),\n",
       " (\"'has\", 'NNP'),\n",
       " (\"'\", 'POS'),\n",
       " (',', ','),\n",
       " (\"'used\", 'VBD'),\n",
       " (\"'\", \"''\"),\n",
       " (',', ','),\n",
       " (\"'allegra\", 'NNP'),\n",
       " (\"'\", 'POS'),\n",
       " (',', ','),\n",
       " (\"'also\", 'NNP'),\n",
       " (\"'\", 'POS'),\n",
       " (',', ','),\n",
       " (\"'she\", 'NNP'),\n",
       " (\"'\", 'POS'),\n",
       " (',', ','),\n",
       " (\"'used\", 'VBD'),\n",
       " (\"'\", \"''\"),\n",
       " (',', ','),\n",
       " (\"'that\", 'WP'),\n",
       " (\"'\", \"''\"),\n",
       " (',', ','),\n",
       " (\"'last\", \"''\"),\n",
       " (\"'\", \"''\"),\n",
       " (',', ','),\n",
       " (\"'summer\", \"''\"),\n",
       " (\"'\", \"''\"),\n",
       " (',', ','),\n",
       " (\"'and\", 'NNP'),\n",
       " (\"'\", 'POS'),\n",
       " (',', ','),\n",
       " (\"'she\", 'NNP'),\n",
       " (\"'\", 'POS'),\n",
       " (',', ','),\n",
       " (\"'began\", 'NNP'),\n",
       " (\"'\", 'POS'),\n",
       " (',', ','),\n",
       " (\"'using\", 'VBG'),\n",
       " (\"'\", \"''\"),\n",
       " (',', ','),\n",
       " (\"'it\", 'NNP'),\n",
       " (\"'\", 'POS'),\n",
       " (',', ','),\n",
       " (\"'again\", \"''\"),\n",
       " (\"'\", \"''\"),\n",
       " (',', ','),\n",
       " (\"'two\", 'NNP'),\n",
       " (\"'\", 'POS'),\n",
       " (',', ','),\n",
       " (\"'weeks\", \"''\"),\n",
       " (\"'\", \"''\"),\n",
       " (',', ','),\n",
       " (\"'ago\", \"''\"),\n",
       " (\"'\", \"''\"),\n",
       " (',', ','),\n",
       " (\"'it\", 'NNP'),\n",
       " (\"'\", 'POS'),\n",
       " (',', ','),\n",
       " (\"'does\", 'NNS'),\n",
       " (\"'\", 'POS'),\n",
       " (',', ','),\n",
       " (\"'not\", 'NNP'),\n",
       " (\"'\", 'POS'),\n",
       " (',', ','),\n",
       " (\"'appear\", \"''\"),\n",
       " (\"'\", \"''\"),\n",
       " (',', ','),\n",
       " (\"'to\", 'NNP'),\n",
       " (\"'\", 'POS'),\n",
       " (',', ','),\n",
       " (\"'be\", 'NNP'),\n",
       " (\"'\", 'POS'),\n",
       " (',', ','),\n",
       " (\"'working\", 'VBG'),\n",
       " (\"'\", \"''\"),\n",
       " (',', ','),\n",
       " (\"'very\", 'NNP'),\n",
       " (\"'\", 'POS'),\n",
       " (',', ','),\n",
       " (\"'well\", 'NNP'),\n",
       " (\"'\", 'POS'),\n",
       " (',', ','),\n",
       " (\"'she\", 'NNP'),\n",
       " (\"'\", 'POS'),\n",
       " (',', ','),\n",
       " (\"'has\", 'NNP'),\n",
       " (\"'\", 'POS'),\n",
       " (',', ','),\n",
       " (\"'used\", 'VBD'),\n",
       " (\"'\", \"''\"),\n",
       " (',', ','),\n",
       " (\"'over-the-counter\", 'NNP'),\n",
       " (\"'\", 'POS'),\n",
       " (',', ','),\n",
       " (\"'sprays\", 'NNS'),\n",
       " (\"'\", 'POS'),\n",
       " (',', ','),\n",
       " (\"'but\", 'NNP'),\n",
       " (\"'\", 'POS'),\n",
       " (',', ','),\n",
       " (\"'no\", 'NNP'),\n",
       " (\"'\", 'POS'),\n",
       " (',', ','),\n",
       " (\"'prescription\", 'NN'),\n",
       " (\"'\", \"''\"),\n",
       " (',', ','),\n",
       " (\"'nasal\", 'NNP'),\n",
       " (\"'\", 'POS'),\n",
       " (',', ','),\n",
       " (\"'sprays\", 'NNS'),\n",
       " (\"'\", 'POS'),\n",
       " (',', ','),\n",
       " (\"'she\", 'NNP'),\n",
       " (\"'\", 'POS'),\n",
       " (',', ','),\n",
       " (\"'does\", 'NNS'),\n",
       " (\"'\", 'POS'),\n",
       " (',', ','),\n",
       " (\"'have\", 'VBP'),\n",
       " (\"'\", \"''\"),\n",
       " (',', ','),\n",
       " (\"'asthma\", 'NNP'),\n",
       " (\"'\", 'POS'),\n",
       " (',', ','),\n",
       " (\"'but\", 'NNP'),\n",
       " (\"'\", 'POS'),\n",
       " (',', ','),\n",
       " (\"'doest\", 'JJS'),\n",
       " (\"'\", \"''\"),\n",
       " (',', ','),\n",
       " (\"'not\", 'NNP'),\n",
       " (\"'\", 'POS'),\n",
       " (',', ','),\n",
       " (\"'require\", 'NNP'),\n",
       " (\"'\", 'POS'),\n",
       " (',', ','),\n",
       " (\"'daily\", 'RB'),\n",
       " (\"'\", 'POS'),\n",
       " (',', ','),\n",
       " (\"'medication\", 'NN'),\n",
       " (\"'\", \"''\"),\n",
       " (',', ','),\n",
       " (\"'for\", 'NNP'),\n",
       " (\"'\", 'POS'),\n",
       " (',', ','),\n",
       " (\"'this\", 'NNP'),\n",
       " (\"'\", 'POS'),\n",
       " (',', ','),\n",
       " (\"'and\", 'NNP'),\n",
       " (\"'\", 'POS'),\n",
       " (',', ','),\n",
       " (\"'does\", 'NNS'),\n",
       " (\"'\", 'POS'),\n",
       " (',', ','),\n",
       " (\"'not\", 'NNP'),\n",
       " (\"'\", 'POS'),\n",
       " (',', ','),\n",
       " (\"'think\", \"''\"),\n",
       " (\"'\", \"''\"),\n",
       " (',', ','),\n",
       " (\"'it\", 'NNP'),\n",
       " (\"'\", 'POS'),\n",
       " (',', ','),\n",
       " (\"'is\", 'NNP'),\n",
       " (\"'\", 'POS'),\n",
       " (',', ','),\n",
       " (\"'flaring\", 'VBG'),\n",
       " (\"'\", \"''\"),\n",
       " (',', ','),\n",
       " (\"'up\", 'NNP'),\n",
       " (\"'\", 'POS'),\n",
       " (',', ','),\n",
       " (\"'medications\", 'NNS'),\n",
       " (\"'\", 'POS'),\n",
       " (',', ','),\n",
       " (\"'her\", 'PRP'),\n",
       " (\"'\", \"''\"),\n",
       " (',', ','),\n",
       " (\"'only\", 'RB'),\n",
       " (\"'\", \"''\"),\n",
       " (',', ','),\n",
       " (\"'medication\", 'NNP'),\n",
       " (\"'\", 'POS'),\n",
       " (',', ','),\n",
       " (\"'currently\", 'RB'),\n",
       " (\"'\", \"''\"),\n",
       " (',', ','),\n",
       " (\"'is\", 'NNP'),\n",
       " (\"'\", 'POS'),\n",
       " (',', ','),\n",
       " (\"'ortho\", 'NNP'),\n",
       " (\"'\", 'POS'),\n",
       " (',', ','),\n",
       " (\"'tri-cyclen\", 'NNP'),\n",
       " (\"'\", 'POS'),\n",
       " (',', ','),\n",
       " (\"'and\", 'NNP'),\n",
       " (\"'\", 'POS'),\n",
       " (',', ','),\n",
       " (\"'the\", 'NNP'),\n",
       " (\"'\", 'POS'),\n",
       " (',', ','),\n",
       " (\"'allegra\", 'NNP'),\n",
       " (\"'\", 'POS'),\n",
       " (',', ','),\n",
       " (\"'allergies\", 'NNS'),\n",
       " (\"'\", 'POS'),\n",
       " (',', ','),\n",
       " (\"'she\", 'NNP'),\n",
       " (\"'\", 'POS'),\n",
       " (',', ','),\n",
       " (\"'has\", 'NNP'),\n",
       " (\"'\", 'POS'),\n",
       " (',', ','),\n",
       " (\"'no\", 'NNP'),\n",
       " (\"'\", 'POS'),\n",
       " (',', ','),\n",
       " (\"'known\", \"''\"),\n",
       " (\"'\", \"''\"),\n",
       " (',', ','),\n",
       " (\"'medicine\", 'NNP'),\n",
       " (\"'\", 'POS'),\n",
       " (',', ','),\n",
       " (\"'allergies\", 'NNS'),\n",
       " (\"'\", 'POS'),\n",
       " (',', ','),\n",
       " (\"'objectivevitals\", 'NNS'),\n",
       " (\"'\", 'POS'),\n",
       " (',', ','),\n",
       " (\"'weight\", 'NNP'),\n",
       " (\"'\", 'POS'),\n",
       " (',', ','),\n",
       " (\"'was\", 'NNP'),\n",
       " (\"'\", 'POS'),\n",
       " (',', ','),\n",
       " (\"'pounds\", 'NNS'),\n",
       " (\"'\", 'POS'),\n",
       " (',', ','),\n",
       " (\"'and\", 'NNP'),\n",
       " (\"'\", 'POS'),\n",
       " (',', ','),\n",
       " (\"'blood\", 'NNP'),\n",
       " (\"'\", 'POS'),\n",
       " (',', ','),\n",
       " (\"'pressure\", 'NN'),\n",
       " (\"'\", \"''\"),\n",
       " (',', ','),\n",
       " (\"'/\", 'NNP'),\n",
       " (\"'\", 'POS'),\n",
       " (',', ','),\n",
       " (\"'heent\", 'NNP'),\n",
       " (\"'\", 'POS'),\n",
       " (',', ','),\n",
       " (\"'her\", 'PRP'),\n",
       " (\"'\", \"''\"),\n",
       " (',', ','),\n",
       " (\"'throat\", 'NNP'),\n",
       " (\"'\", 'POS'),\n",
       " (',', ','),\n",
       " (\"'was\", 'NNP'),\n",
       " (\"'\", 'POS'),\n",
       " (',', ','),\n",
       " (\"'mildly\", 'RB'),\n",
       " (\"'\", \"''\"),\n",
       " (',', ','),\n",
       " (\"'erythematous\", 'JJ'),\n",
       " (\"'\", \"''\"),\n",
       " (',', ','),\n",
       " (\"'without\", 'IN'),\n",
       " (\"'\", \"''\"),\n",
       " (',', ','),\n",
       " (\"'exudate\", 'NNP'),\n",
       " (\"'\", 'POS'),\n",
       " (',', ','),\n",
       " (\"'nasal\", 'NNP'),\n",
       " (\"'\", 'POS'),\n",
       " (',', ','),\n",
       " (\"'mucosa\", 'NNP'),\n",
       " (\"'\", 'POS'),\n",
       " (',', ','),\n",
       " (\"'was\", 'NNP'),\n",
       " (\"'\", 'POS'),\n",
       " (',', ','),\n",
       " (\"'erythematous\", 'JJ'),\n",
       " (\"'\", \"''\"),\n",
       " (',', ','),\n",
       " (\"'and\", 'NNP'),\n",
       " (\"'\", 'POS'),\n",
       " (',', ','),\n",
       " (\"'swollen\", 'NNP'),\n",
       " (\"'\", 'POS'),\n",
       " (',', ','),\n",
       " (\"'only\", 'RB'),\n",
       " (\"'\", \"''\"),\n",
       " (',', ','),\n",
       " (\"'clear\", 'IN'),\n",
       " (\"'\", \"''\"),\n",
       " (',', ','),\n",
       " (\"'drainage\", 'NN'),\n",
       " (\"'\", \"''\"),\n",
       " (',', ','),\n",
       " (\"'was\", 'NNP'),\n",
       " (\"'\", 'POS'),\n",
       " (',', ','),\n",
       " (\"'seen\", \"''\"),\n",
       " (\"'\", \"''\"),\n",
       " (',', ','),\n",
       " (\"'tms\", 'NNP'),\n",
       " (\"'\", 'POS'),\n",
       " (',', ','),\n",
       " (\"'were\", 'EX'),\n",
       " (\"'\", \"''\"),\n",
       " (',', ','),\n",
       " (\"'clear\", 'IN'),\n",
       " (\"'\", \"''\"),\n",
       " (',', ','),\n",
       " (\"'neck\", 'NNP'),\n",
       " (\"'\", 'POS'),\n",
       " (',', ','),\n",
       " (\"'supple\", \"''\"),\n",
       " (\"'\", \"''\"),\n",
       " (',', ','),\n",
       " (\"'without\", 'IN'),\n",
       " (\"'\", \"''\"),\n",
       " (',', ','),\n",
       " (\"'adenopathy\", \"''\"),\n",
       " (\"'\", \"''\"),\n",
       " (',', ','),\n",
       " (\"'lungs\", 'NNS'),\n",
       " (\"'\", 'POS'),\n",
       " (',', ','),\n",
       " (\"'clear\", \"''\"),\n",
       " (\"'\", \"''\"),\n",
       " (',', ','),\n",
       " (\"'assessment\", 'NNP'),\n",
       " (\"'\", 'POS'),\n",
       " (',', ','),\n",
       " (\"'allergic\", 'NNP'),\n",
       " (\"'\", 'POS'),\n",
       " (',', ','),\n",
       " (\"'rhinitis\", \"''\"),\n",
       " (\"'\", \"''\"),\n",
       " (',', ','),\n",
       " (\"'plan\", 'NNP'),\n",
       " (\"'\", 'POS'),\n",
       " (',', ','),\n",
       " (\"'she\", 'NNP'),\n",
       " (\"'\", 'POS'),\n",
       " (',', ','),\n",
       " (\"'will\", 'NNP'),\n",
       " (\"'\", 'POS'),\n",
       " (',', ','),\n",
       " (\"'try\", 'NN'),\n",
       " (\"'\", \"''\"),\n",
       " (',', ','),\n",
       " (\"'zyrtec\", \"''\"),\n",
       " (\"'\", \"''\"),\n",
       " (',', ','),\n",
       " (\"'instead\", \"''\"),\n",
       " (\"'\", \"''\"),\n",
       " (',', ','),\n",
       " (\"'of\", 'NNP'),\n",
       " (\"'\", 'POS'),\n",
       " (',', ','),\n",
       " (\"'allegra\", 'NNP'),\n",
       " (\"'\", 'POS'),\n",
       " (',', ','),\n",
       " (\"'again\", \"''\"),\n",
       " (\"'\", \"''\"),\n",
       " (',', ','),\n",
       " (\"'another\", 'PRP'),\n",
       " (\"'\", \"''\"),\n",
       " (',', ','),\n",
       " (\"'option\", 'NNP'),\n",
       " (\"'\", 'POS'),\n",
       " (',', ','),\n",
       " (\"'will\", 'NNP'),\n",
       " (\"'\", 'POS'),\n",
       " (',', ','),\n",
       " (\"'be\", 'NNP'),\n",
       " (\"'\", 'POS'),\n",
       " (',', ','),\n",
       " (\"'to\", 'NNP'),\n",
       " (\"'\", 'POS'),\n",
       " (',', ','),\n",
       " (\"'use\", 'IN'),\n",
       " (\"'\", \"''\"),\n",
       " (',', ','),\n",
       " (\"'loratadine\", 'NNP'),\n",
       " (\"'\", 'POS'),\n",
       " (',', ','),\n",
       " (\"'she\", 'NNP'),\n",
       " (\"'\", 'POS'),\n",
       " (',', ','),\n",
       " (\"'does\", 'NNS'),\n",
       " (\"'\", 'POS'),\n",
       " (',', ','),\n",
       " (\"'not\", 'NNP'),\n",
       " (\"'\", 'POS'),\n",
       " (',', ','),\n",
       " (\"'think\", \"''\"),\n",
       " (\"'\", \"''\"),\n",
       " (',', ','),\n",
       " (\"'she\", 'NNP'),\n",
       " (\"'\", 'POS'),\n",
       " (',', ','),\n",
       " (\"'has\", 'NNP'),\n",
       " (\"'\", 'POS'),\n",
       " (',', ','),\n",
       " (\"'prescription\", 'NN'),\n",
       " (\"'\", \"''\"),\n",
       " (',', ','),\n",
       " (\"'coverage\", 'NN'),\n",
       " (\"'\", \"''\"),\n",
       " (',', ','),\n",
       " (\"'so\", 'NNP'),\n",
       " (\"'\", 'POS'),\n",
       " (',', ','),\n",
       " (\"'that\", 'WP'),\n",
       " (\"'\", \"''\"),\n",
       " (',', ','),\n",
       " (\"'might\", 'NNP'),\n",
       " (\"'\", 'POS'),\n",
       " (',', ','),\n",
       " (\"'be\", 'NNP'),\n",
       " (\"'\", 'POS'),\n",
       " (',', ','),\n",
       " (\"'cheaper\", 'NNP'),\n",
       " (\"'\", 'POS'),\n",
       " (',', ','),\n",
       " (\"'samples\", 'NNS'),\n",
       " (\"'\", 'POS'),\n",
       " (',', ','),\n",
       " (\"'of\", 'NNP'),\n",
       " (\"'\", 'POS'),\n",
       " (',', ','),\n",
       " (\"'nasonex\", 'NNP'),\n",
       " (\"'\", 'POS'),\n",
       " (',', ','),\n",
       " (\"'two\", 'NNP'),\n",
       " (\"'\", 'POS'),\n",
       " (',', ','),\n",
       " (\"'sprays\", 'NNS'),\n",
       " (\"'\", 'POS'),\n",
       " (',', ','),\n",
       " (\"'in\", 'NNP'),\n",
       " (\"'\", 'POS'),\n",
       " (',', ','),\n",
       " (\"'each\", 'NNP'),\n",
       " (\"'\", 'POS'),\n",
       " (',', ','),\n",
       " (\"'nostril\", 'NNP'),\n",
       " (\"'\", 'POS'),\n",
       " (',', ','),\n",
       " (\"'given\", \"''\"),\n",
       " (\"'\", \"''\"),\n",
       " (',', ','),\n",
       " (\"'for\", 'NNP'),\n",
       " (\"'\", 'POS'),\n",
       " (',', ','),\n",
       " (\"'three\", \"''\"),\n",
       " (\"'\", \"''\"),\n",
       " (',', ','),\n",
       " (\"'weeks\", \"''\"),\n",
       " (\"'\", \"''\"),\n",
       " (',', ','),\n",
       " (\"'\", \"''\"),\n",
       " ('a', 'DT'),\n",
       " (\"'\", \"''\"),\n",
       " (',', ','),\n",
       " (\"'prescription\", 'NNP'),\n",
       " (\"'\", 'POS'),\n",
       " (',', ','),\n",
       " (\"'was\", 'NNP'),\n",
       " (\"'\", 'POS'),\n",
       " (',', ','),\n",
       " (\"'written\", \"''\"),\n",
       " (\"'\", \"''\"),\n",
       " (',', ','),\n",
       " (\"'as\", 'NNP'),\n",
       " (\"'\", 'POS'),\n",
       " (',', ','),\n",
       " (\"'well\", 'NNP'),\n",
       " (\"'\", 'POS'),\n",
       " (']', 'NN')]"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data['POSTags'][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# data['transcription']=data['transcription'].replace(['#',':,',': ,',';','$'], [' ',' ',' ',' ',' '], regex=True)\n",
    "# data['transcription']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# REACH GOAL\n",
    "# from nltk.tokenize import sent_tokenize\n",
    "# data[\"sent_token\"] = data[\"transcription\"].apply(lambda x: sent_tokenize(x))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data[\"sent_token\"][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from collections import Counter\n",
    "dictionary= data['tokenized_sents'].transform(lambda x: Counter(x)).sum()\n",
    "dictionary\n",
    "\n",
    "for k in sorted(dictionary, key=dictionary.get, reverse=True):\n",
    "    print(k, dictionary[k])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data['tokenized_sents'] = data['tokenized_sents'].astype('str')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data['POSTags'][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_all = data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nltk.help.upenn_tagset()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data['Nouns'] = data['POSTags'].apply(lambda x: [(t[0], t[1]) for t in x if t[1]=='NN' or t[1]=='NNP' or t[1]=='NNS' or t[1]=='NNPS'])\n",
    "\n",
    "\n",
    "data['Nouns']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data['Nouns']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data['Nouns'][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.corpus import stopwords\n",
    "stop = stopwords.words('english')\n",
    "\n",
    "data['post_stopwords'] = data['tokenized_sents'].apply(lambda x: [item for item in x if item not in stop])\n",
    "data.sample(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data['tokenized_sents']=data['tokenized_sents'].astype('str')\n",
    "data['tokenized_sents']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data['tokens'] = data['tokenized_sents'].str.split().str.len()\n",
    "data.sample(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data['medical_specialty'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#disproportion of corpora\n",
    "data['medical_specialty'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data['medical_specialty'].nunique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# columns_to_remove = [' Office Notes',  'SOAP / Chart / Progress Notes', 'Letters', 'IME-QME-Work Comp etc.','Hospice - Palliative Care',' Discharge Summary' ]\n",
    "\n",
    "# med_specialties= data['medical_specialty']\n",
    "\n",
    "# for column in med_specialties:\n",
    "#     med_specialties != columns_to_remove"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = data[(data['medical_specialty'] != ' Discharge Summary')& \n",
    "            (data['medical_specialty'] != ' Office Notes') & \n",
    "            (data['medical_specialty'] != ' SOAP / Chart / Progress Notes') &\n",
    "            (data['medical_specialty'] != ' Letters') &\n",
    "            (data['medical_specialty'] != ' IME-QME-Work Comp etc.') &\n",
    "           (data['medical_specialty'] != ' Hospice - Palliative Care')&\n",
    "           (data['medical_specialty'] != ' Emergency Room Reports') &\n",
    "            (data['medical_specialty'] != ' Autopsy')]\n",
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Getting the mean and median across all tokens \n",
    "print(data['tokens'].mean())\n",
    "print(data['tokens'].median())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data['tokens'].value_counts().sample(50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data['medical_specialty'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.groupby('medical_specialty')['tokens'].agg(['count', 'mean', 'median']).sort_values(by='count',ascending = False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# A good snapshot: in our corpus there is a great number of texts for Surgery, but for practices like Psychiatry and \n",
    "#Immunology very few. Nonetheless, mean and median of tokes are high for those categories, which means that the corpora\n",
    "#are long\n",
    "data.groupby('medical_specialty')['tokens'].agg(['count', 'mean', 'median']).sort_values(by='count',ascending = False).plot(kind='bar', figsize=(20,10))\n",
    "plt.ylabel(\"Tokens number\" )\n",
    "plt.xlabel(\"Medical Specialties\")\n",
    "plt.grid()\n",
    "plt.xticks(rotation = 90)\n",
    "plt.legend(fancybox= True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Decided to group some categories in sleep and Pain, Dermatology and Cosmetic Surgery In SKIN cosmetics, Chiropratic and Phisical med Rehab, \n",
    "#Bariatrics and Nutritions in Dietology,                \n",
    "# data = data.replace({' Sleep Medicine': 'Sleep and Pain', ' Pain Management': 'Sleep and Pain'})\n",
    "# data\n",
    "# # Combining similar offenses together\n",
    "data = data.replace({' Sleep Medicine': \" Sleep and Pain\", ' Pain Management': \" Sleep and Pain\"})\n",
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data['medical_specialty'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data['medical_specialty'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data['medical_specialty'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Combining similar offenses together\n",
    "#Group sleep and Pain, Dermatology and Cosmetic Surgery In SKIN cosmetics, Chiropratic and Phisical med Rehab, \n",
    "#Bariatrics and Nutritions in Dietology,                \n",
    "# data = data.replace({' Sleep Medicine': 'Sleep and Pain', ' Pain Management': 'Sleep and Pain'})\n",
    "# data\n",
    "data = data.replace({' Cosmetic / Plastic Surgery': \" SKIN cosmetics\", ' Dermatology': \" SKIN cosmetics\"})\n",
    "data['medical_specialty'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = data.replace({' Chiropractic': \" Physical Therapy\", ' Physical Medicine - Rehab': \" Physical Therapy\"})\n",
    "data['medical_specialty'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = data.replace({' Bariatrics': \" Dietetics\", ' Diets and Nutritions': \" Dietetics\"})\n",
    "data['medical_specialty'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = data.replace({' Neurology': \" Neurologists\", ' Neurosurgery': \" Neurologists\"})\n",
    "data['medical_specialty'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Final count of medical specialties (for now)\n",
    "data = data.replace({' Lab Medicine - Pathology': \" Pathology\"})\n",
    "data['medical_specialty'].nunique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Setting a cutoff lowerbound (250 tokens) and upperbound (1000) for the number of tokens\n",
    "data= data[(data['tokens'] >= 250) & (data['tokens'] <= 1000)]\n",
    "print(data['tokens'].min())\n",
    "print(data['tokens'].max())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data['medical_specialty'].nunique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data['medical_specialty'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data['medical_specialty'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(data['tokens'].min())\n",
    "print(data['tokens'].max())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cleaned snapshot\n",
    "data.groupby('medical_specialty')['tokens'].agg(['count', 'mean', 'median']).sort_values(by='count',ascending = False).plot(kind='bar', figsize=(20,10))\n",
    "plt.ylabel(\"Tokens number\" )\n",
    "plt.xlabel(\"Medical Specialties\")\n",
    "plt.grid()\n",
    "plt.xticks(rotation = 90)\n",
    "plt.legend(fancybox= True)\n",
    "plt.savefig('Corpus view')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.groupby('medical_specialty')['tokens'].agg(['count', 'mean', 'median']).sort_values(by='count',ascending = False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "del data['sample_name']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.sample(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import Counter\n",
    "dictionary= data[\"post_stopwords\"].transform(lambda x: Counter(x)).sum()\n",
    "dictionary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for k in sorted(dictionary, key=dictionary.get, reverse=True):\n",
    "    print(k, dictionary[k])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.setrecursionlimit(10000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # #stemming \n",
    "# from nltk.stem.snowball import SnowballStemmer\n",
    "\n",
    "# # Use English stemmer.\n",
    "# stemmer = SnowballStemmer(\"english\")\n",
    "\n",
    "\n",
    "# # data=data['Stemmed_column']=data['post_stopwords'].apply(lambda x : [porter_stemmer.stem(y) for y in x])\n",
    "# # data\n",
    "\n",
    "# data=data['stemmed'] = data['post_stopwords'].apply(lambda x: [stemmer.stem(y) for y in x]) # Stem every word.\n",
    "# data\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.stem.wordnet import WordNetLemmatizer\n",
    "\n",
    "lmtzr = WordNetLemmatizer()\n",
    "data['lemmatize'] = data['post_stopwords'].apply(lambda lst:[lmtzr.lemmatize(word) for word in lst])\n",
    "\n",
    "print(data['lemmatize'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data=data.reset_index(drop=True)\n",
    "data.sample(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data['lemmatize']= data['lemmatize'].astype('str')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.sample(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(data['POSTags'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Here are the 5 steps to create a chatbot in Python from scratch:\n",
    "\n",
    "# Import and load the data file\n",
    "# Preprocess data\n",
    "# Create training and testing data\n",
    "# Build the model\n",
    "# Predict the response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Creating the label and Creating the Training and Test Datasets\n",
    "#first thing to do is to separate out the label from the numerical dataframe\n",
    "X = data.drop(\"medical_specialty\", axis=1)\n",
    "y = data[\"medical_specialty\"]\n",
    "#Imput is the X dataset. \n",
    "print(X.shape, y.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y.unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import the necessaried dependecies \n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "from sklearn.preprocessing import StandardScaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(data['lemmatize'], y, test_size=0.30, random_state=100)\n",
    "\n",
    "print(data.shape); print(X_train.shape); print(X_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use train_test_split to create training and testing data\n",
    "# X_train, X_test, y_train, y_test = train_test_split(X, y, random_state=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TF-IDF is an acronym that stands for 'Term Frequency-Inverse Document Frequency'. \n",
    "#It is used as a weighting factor in text mining applications.\n",
    "\n",
    "# Term Frequency (TF): This summarizes the normalized Term Frequency within a document.\n",
    "\n",
    "# Inverse Document Frequency (IDF): This reduces the weight of terms that appear a lot across documents. \n",
    "#In simple terms, TF-IDF attempts to highlight important words which are frequent in a document but not across documents. \n",
    "#We will work on creating TF-IDF vectors for our documents."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# The first line of code below imports the TfidfVectorizer from 'sklearn.feature_extraction.text' module\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "\n",
    "# The second line initializes the TfidfVectorizer object, called 'vectorizer_tfidf\n",
    "vectorizer_tfidf = TfidfVectorizer(stop_words='english', max_df=0.7)\n",
    "\n",
    "# The third line fits and transforms the training data.\n",
    "train_tfIdf = vectorizer_tfidf.fit_transform(X_train.values.astype('U'))\n",
    "\n",
    "# The fourth line of code transforms the test data, while the fifth line prints the first 10 features.\n",
    "test_tfIdf = vectorizer_tfidf.transform(X_test.values.astype('U'))\n",
    "\n",
    "print(vectorizer_tfidf.get_feature_names()[:10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Let's look at the shape of the transformed TF-IDF train and test datasets. \n",
    "# The following line of code performs this task.\n",
    "print(train_tfIdf.shape); print(test_tfIdf.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn import metrics\n",
    "\n",
    "# Multinomial Naive Bayes classifier\n",
    "nb_classifier = MultinomialNB()\n",
    "\n",
    "# The fourth line of code fits the classifier on the training data\n",
    "nb_classifier.fit(train_tfIdf, y_train)\n",
    "\n",
    "# our model is trained and it is ready to generate predictions on the unseen data. \n",
    "# This is performed in the fifth line of code, while the sixth line prints the predicted class for the first 10 records in the test data.\n",
    "pred2 = nb_classifier.predict(test_tfIdf) \n",
    "print(pred2[:10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate the accuracy score: score\n",
    "accuracy_tfidf = metrics.accuracy_score(y_test, pred2)\n",
    "print(accuracy_tfidf)\n",
    "\n",
    "Conf_metrics_tfidf = metrics.confusion_matrix(y_test, pred2)\n",
    "print(Conf_metrics_tfidf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "labels= [' Dietetics', ' Neurologists', ' Dentistry',\n",
    "       ' Cardiovascular / Pulmonary', ' Urology', ' General Medicine',\n",
    "       ' Surgery', ' Speech - Language', ' Sleep and Pain',\n",
    "       ' Rheumatology', ' Radiology', ' Psychiatry / Psychology',\n",
    "       ' Podiatry', ' Physical Therapy', ' Pediatrics - Neonatal',\n",
    "       ' Orthopedic', ' Ophthalmology', ' Obstetrics / Gynecology',\n",
    "       ' Nephrology', ' Pathology', ' Hematology - Oncology',\n",
    "       ' Gastroenterology', ' ENT - Otolaryngology', ' Endocrinology',\n",
    "       ' SKIN cosmetics', ' Consult - History and Phy.',\n",
    "       ' Allergy / Immunology']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(786/3160) #Baseline accuracy: assegni una label al test set in base al train set. c'e' un modello che lo fa sklearn "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate classification report\n",
    "from sklearn.metrics import classification_report\n",
    "print(classification_report(y_test,pred2,\n",
    "                            target_names=labels))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "classifier = RandomForestClassifier(n_estimators = 200, criterion = 'entropy', random_state = 100)\n",
    "\n",
    "rf=classifier.fit(train_tfIdf, y_train)\n",
    "rf.score(test_tfIdf, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predRF = classifier.predict(test_tfIdf) \n",
    "print(predRF[:10])\n",
    "\n",
    "# Calculate the accuracy score\n",
    "accuracy_RF = metrics.accuracy_score(y_test, predRF)\n",
    "print(accuracy_RF)\n",
    "\n",
    "Conf_metrics_RF = metrics.confusion_matrix(y_test, predRF)\n",
    "print(Conf_metrics_RF)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "labels= [' Dietetics', ' Neurologists', ' Dentistry',\n",
    "       ' Cardiovascular / Pulmonary', ' Urology', ' General Medicine',\n",
    "       ' Surgery', ' Speech - Language', ' Sleep and Pain',\n",
    "       ' Rheumatology', ' Radiology', ' Psychiatry / Psychology',\n",
    "       ' Podiatry', ' Physical Therapy', ' Pediatrics - Neonatal',\n",
    "       ' Orthopedic', ' Ophthalmology', ' Obstetrics / Gynecology',\n",
    "       ' Nephrology', ' Pathology', ' Hematology - Oncology',\n",
    "       ' Gastroenterology', ' ENT - Otolaryngology', ' Endocrinology',\n",
    "       ' SKIN cosmetics', ' Consult - History and Phy.',\n",
    "       ' Allergy / Immunology']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We can sort the features by their importance. Which feature is more importance for the prediction. \n",
    "sorted(zip(rf.feature_importances_, labels), reverse=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate classification report\n",
    "from sklearn.metrics import classification_report\n",
    "print(classification_report(y_test, predRF,\n",
    "                            target_names=labels))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# #It is really important to scale our data before using multilayer perceptron models. Using MinMaxscaler (or StandardScaler)in this case\n",
    "# #Without scaling, it is often difficult for the training cycle to converge. \n",
    "\n",
    "# # Create a StandardScater model and fit it to the training data\n",
    "# X_scaler = StandardScaler().fit(X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# #Remember to scale both the training and testing data\n",
    "# X_train_scaled = X_scaler.transform(X_train)\n",
    "# X_test_scaled = X_scaler.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# X_train_scaled"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Step 1: Label-encode data set\n",
    "# label_encoder = LabelEncoder()\n",
    "# label_encoder.fit(y_train)\n",
    "# encoded_y_train = label_encoder.transform(y_train)\n",
    "# encoded_y_test = label_encoder.transform(y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Step 2: Convert encoded labels to one-hot-encoding\n",
    "# y_train_categorical = to_categorical(encoded_y_train)\n",
    "# y_test_categorical = to_categorical(encoded_y_test)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# y_test_categorical"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# y_train_categorical"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from sklearn import tree\n",
    "# clf = tree.DecisionTreeClassifier()\n",
    "# clf = clf.fit(X_train, y_train)\n",
    "# clf.score(X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Create a random forest classifier\n",
    "# from sklearn.ensemble import RandomForestClassifier\n",
    "# rf = RandomForestClassifier(n_estimators=200)\n",
    "# rf = rf.fit(X_train, y_train)\n",
    "# rf.score(X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
